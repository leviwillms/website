# Alignment False-positives

Published: true

Following yesterdays session I was able to produce an alignment of the ppx text fragments to the mistral text fragments. However, I found a number of issues upon further analysis. This is the current run, indicating a 99.74% match rate. However, as I will note in my points below the **quality** of the matches is rather flawed.

```bash
Aligning "paper" [1546/1546] ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00

Alignment complete:
Total PPX fragments processed: 1546
Fragments with alignments: 1542
Match rate: 99.74%
Total time elapsed: 541.00s

Confidence Distribution:
Min: 0.4583
Max: 1.0000
Mean: 0.9155
Median: 1.0000

Fragments with confidence >= 0.45: 1542/1546
```

1. The system identifies the first candidate for a string match as a correct alignment between ppx and mistral. I've temporarily written some code to take the best candidate over the shortest token span to produce the match. However, further investigation will be required to determine the actual candidate.
2. Related to the point above, we will get a result like the following in example 1.1

## 1.0 Set of examples

The following are examples used referencing a `match_score >= 10` and ordered by confidence. Upon manual evaluation of a small (4) subset of records it is impressively accurate and finding the best candidate for mapping a `mistral_fragment` to a `text_fragment`.

The following query was used: `SELECT * FROM fragment_alignments WHERE confidence < 1 AND match_score >= 10 ORDER BY confidence ASC;`. Which, if we assume that all mappings are correct for a `match_score >= 10`, we can assume the following accuracy calculations:

- **1:1 match (confidence = 1.0)**: 865
- **Correct (confidence < 1, score >= 10)**: 465
- **Potentially incorrect**: 212

Totals:

- 56.1% exact match
- 86.3% correct
- 13.8% potentially incorrect

### Example 1.1

```json
text_fragment = {
    "id": 482,
    "text": "000020"
}

mistral_text_fragment = {
    "id": 215,
    "text": "Training setup We train our models using TensorFlow[31]. We use the standard RMSPropOptimizer with both decay and momentum set to 0.9. We use batch normalization after every layer, and the standard weight decay is set to 0.00004. Following MobileNetV1[27] setup we use initial learning rate of 0.045, and learning rate decay rate of 0.98 per epoch. We use 16 GPU asynchronous workers, and a batch size of 96."
}

Fragment Alignment = {
    "id": 3089,
    "ppx_fragment_id": 482,
    "mistral_fragment_id": 215,
    "token_start": 0,
    "token_end": 116,
    "match_score": 4,
    "confidence": 0.8,
    "alignment_method": "dp"
}
```

### Example 1.2

```json

text_fragment = {
    "ID": 488,
    "text": "MobileNetV2, that improves the state of the art perfor-"
}
text_fragment = {
    "id": 494,
    "text": "sizes. We also describe effi cient ways of applying these"
}

mistral_text_fragment = {
    "id": 9,
    "text": "In this paper we describe a new mobile architecture, MobileNetV2, that improves the state of the art performance of mobile models on multiple tasks and benchmarks as well as across a spectrum of different model sizes. We also describe efficient ways of applying these mobile models to object detection in a novel framework we call SSDLite. Additionally, we demonstrate how to build mobile semantic segmentation models through a reduced form of DeepLabv3 which we call Mobile DeepLabv3."
}
```

### Example 1.3

This example shows a lower confidence score with still a high match score. It is evidently correct.

```json
text_fragment = {
    "id": 523,
    "text": "thermore, this convolutional module is particularly suit-"
}

mistral_text_fragment = {
    "id": 23,
    "text": "This module can be efficiently implemented using standard operations in any modern framework and allows our models to beat state of the art along multiple performance points using standard benchmarks. Furthermore, this convolutional module is particularly suitable for mobile designs, because it allows to significantly reduce the memory footprint needed during inference by never fully materializing large intermediate tensors. This reduces the need for main memory access in many embedded hardware designs, that provide small amounts of very fast software controlled cache memory."
}
```

### Example 1.4

This is the lowest confidence score with a match_score > 10. It is also correct even with the inability to properly match equations.

```json

text_fragment = {
    "id": 936,
    "text": "N : Rs×s×n → Rs′×s′×n,and B is again a linear"
}

mistral_text_fragment = {
    "id": 185,
    "text": "Bottleneck Residual Block A bottleneck block operator  $\mathcal{F}(x)$  shown in Figure 3b can be expressed as a composition of three operators  $\mathcal{F}(x) = [A\circ \mathcal{N}\circ B]x$  where  $A$  is a linear transformation  $A:\mathcal{R}^{s\times s\times k}\to$ $\mathcal{R}^{s\times s\times n}$ $\mathcal{N}$  is a non-linear per-channel transformation:  $\mathcal{N}:\mathcal{R}^{s\times s\times n}\rightarrow \mathcal{R}^{s'\times s'\times n}$  , and  $B$  is again a linear transformation to the output domain:  $B:\mathcal{R}^{s'\times s'\times n}\rightarrow$ $\mathcal{R}^{s'\times s'\times k'}$"
}

fragment_alignment = {
    "id": 3779,
    "ppx_fragment_id": 936,
    "mistral_fragment_id": 185,
    "token_start": 0,
    "token_end": 246,
    "match_score": 11,
    "confidence": 0.4583333333333333,
    "alignment_method": "dp"
}

```

### Example 1.5

Note that Mistral does not pick up footnotes in the returned data. So any footnote that is found will fail alignment between mistral and ppx. When I reduced the match_score check to be 9 I began to find these common footnote discrepancies. However, there is no telling whether or not these exist in higher matched scores.

Given the lack of reliability in confidence scores < 10, we assume that anything under confidence < 10 cannot be trusted in the current state of the alignment.

```
text_fragment = {
    "id": 1546,
    "text": "is fixed, which would not be the case for almost all B and Γ = BS"
}

mistral_text_fragment = {
    "id": 369,
    "text": "The constraints of the lemma 2 can be empirically validated for real networks and real inputs and hence we can be assured
 that information is indeed preserved. We further show that with respect to initialization, we can be sure that these constraint
s are satisfied with high probability. Note that for random initialization the conditions of lemma 2 are satisfied due to initia
lization symmetries. However even for trained graphs these constraints can be empirically validated by running the network over
valid inputs and verifying that all or most inputs are above the threshold. On Figure 7 we show how this distribution looks for
different MobileNetV2 layers. At step $0$ the activation patterns concentrate around having half of the positive channel (as pre
dicted by initialization symmetries). For fully trained network, while the standard deviation grew significantly, all but the tw
o layers are still above the invertibility thresholds. We believe further study of this is warranted and might lead to helpful i
nsights on network design."
}

fragment_alignment = {
    "id": 4513,
    "ppx_fragment_id": 1546,
    "mistral_fragment_id": 369,
    "token_start": 0,
    "token_end": 204,
    "match_score": 9,
    "confidence": 0.47368421052631576,
    "alignment_method": "dp"
}

```

```
id  | ppx_fragment_id | mistral_fragment_id | token_start | token_end | match_score |     confidence      | alignment_method

------+-----------------+---------------------+-------------+-----------+-------------+---------------------+-----------------
-
 3246 |            1229 |                  38 |           0 |       168 |           9 | 0.47368421052631576 | dp
 4513 |            1546 |                 369 |           0 |       204 |           9 | 0.47368421052631576 | dp
 3259 |            1242 |                  50 |           0 |       221 |           9 |  0.5294117647058824 | dp
 3203 |            1185 |                  30 |           0 |       187 |           9 |                 0.6 | dp
```

## Next Steps

It seems that the vital next steps to determine how actually accurate this system is requires creating a ground-truth set of data. But if we are using mistral as the ground truth, and attempting to map ppx to the ground truth, creating a ground truth for every document would be impossible. So how can we properly evaluate the accuracy while identifying the false positives? Such as the footnote issues identified above?
