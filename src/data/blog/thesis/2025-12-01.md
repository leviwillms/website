# First alignment analysis

Published: true

## 2025-12-01

First Analysis:

```
Analyzing "paper" ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00

Analysis complete:
Total text fragments analyzed: 1546
Fragments with Mistral matches: 857
Match rate: 55.43%
```

If we add in a condition to remove trailing '-' (dashes), then the result becomes:

```
(.venv) levi@ppx:~/ppx$ ppx analyze paper 0-13
Analyzing "paper" ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00

Analysis complete:
Total text fragments analyzed: 1546
Fragments with Mistral matches: 1053
Match rate: 68.11%
```

### Solutions

With the remaining 32% of text fragments we might have to employ a multi-modal solution to determine if the text exists in the reference fragments. We can check a bidirectional encoder such as BERT to understand the similarity. For example, if something is 95% the same characters then we might have a match.

We need to tokenize the `text_fragments` to use some kind of vector matching (subset alignment) between the sub-sections of markdown and the vectors of the `text_fragments`. The objective would be to search through all the markdown and find the sequence of markdown which is the highest _alignment_ to the `text_fragments`. So if our fragments are `ABCDEF` and the best markdown comparison returns a single `ABCEF` sequence then we will assume that is the location of the fragment.

To do this we'll have to compare the text fragment to all sets of markdown sequences. I think it's best here to precompute a markdown hashmap so we can directly search the hashmap to see if it's found.

Then, we can face an interesting problem once this is solved.

1. Determine ways to define a region of markdown.
2. Decide relevant score between sub-md and a query.
3. Determine an algorithm (greedy, DP, etc.) to identify optimal sub-md.
   1. Find score >= c

Another suggestion for the beginning and simplicity of the analysis was to remove the figures (images, tables, etc) from the OCR. This is done through the masking out of the content. Ken suggested to do this so we can focus on the initial problem of just text alignment (and operating under an assumption that querying a corpus of text is unlikely to result in an image).
